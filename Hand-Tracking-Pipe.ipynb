{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "from IPython.display import clear_output, Image, display\n",
    "from PIL import Image as PILImage\n",
    "\n",
    "from src.utils import display_jupyter, display_cv2, detect_initial_point\n",
    "from src.kalman_filter import KalmanFilter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization\n",
    "\n",
    "This section defines the video sources and configures the parameters used in the tracking setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Video path\n",
    "video_path = \"hand_tracking.mp4\"\n",
    "cap = cv2.VideoCapture(0)\n",
    "if not cap.isOpened():\n",
    "    raise IOError(\"Cannot open video file\")\n",
    "\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "canvas = np.zeros((frame_height, frame_width, 3), dtype=np.uint8)\n",
    "\n",
    "# State variables\n",
    "initial_point = None\n",
    "tracking_started = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tracking\n",
    "\n",
    "In this section, we perform the tracking task based on predefined algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tracking with CSRT Tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Tracking using the CSRT tracker from OpenCV\n",
    "\n",
    "# try:\n",
    "    \n",
    "#     # Initialize tracker as none\n",
    "#     tracker = None\n",
    "    \n",
    "#     while True:\n",
    "#         ret, frame = cap.read()\n",
    "#         if not ret:\n",
    "#             cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "#             continue\n",
    "        \n",
    "#         output_frame = frame.copy()\n",
    "        \n",
    "#         # If tracking is not started, look for initial fingertip to start tracking.\n",
    "#         if not tracking_started:\n",
    "            \n",
    "#             # Detect the initial point using the MediaPipe library\n",
    "#             initial_point = detect_initial_point(frame)\n",
    "            \n",
    "#             if initial_point is not None:\n",
    "#                 tracking_started = True\n",
    "#                 print(\"Initial point detected! Starting tracking...\")\n",
    "                \n",
    "#                 # Initialize tracker\n",
    "#                 tracker = cv2.TrackerCSRT_create()  # or cv2.TrackerKCF_create()\n",
    "                \n",
    "#                 # Create bounding box around initial point of 50x50 pixels\n",
    "#                 # The goal of the bounding box is to create an area of interest for the tracker\n",
    "#                 box_size = 50\n",
    "#                 bbox = (\n",
    "#                     initial_point[0] - box_size//2,\n",
    "#                     initial_point[1] - box_size//2,\n",
    "#                     box_size,\n",
    "#                     box_size\n",
    "#                 )\n",
    "#                 tracker.init(frame, bbox)\n",
    "#                 current_point = initial_point\n",
    "        \n",
    "#         if tracking_started:\n",
    "#             # Update tracker\n",
    "#             success, bbox = tracker.update(frame)\n",
    "            \n",
    "#             if success:\n",
    "#                 # Get center point of bounding box for plotting\n",
    "#                 current_point = (\n",
    "#                     int(bbox[0] + bbox[2]//2),\n",
    "#                     int(bbox[1] + bbox[3]//2)\n",
    "#                 )\n",
    "                \n",
    "#                 cv2.circle(output_frame, current_point, 5, (0, 255, 0), -1)\n",
    "#                 cv2.rectangle(output_frame, \n",
    "#                             (int(bbox[0]), int(bbox[1])), \n",
    "#                             (int(bbox[0] + bbox[2]), int(bbox[1] + bbox[3])),\n",
    "#                             (255, 0, 0), 2)\n",
    "#                 cv2.putText(output_frame, \"Tracking Active\", (10, 30),\n",
    "#                            cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "#             else:\n",
    "#                 cv2.putText(output_frame, \"Tracking Lost\", (10, 30),\n",
    "#                            cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "#                 tracking_started = False\n",
    "#         else:\n",
    "#             cv2.putText(output_frame, \"Waiting for pointing gesture...\", (10, 30),\n",
    "#                        cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "        \n",
    "#         # Display the frame in jupyter notebook or OpenCV window\n",
    "#         display_cv2(frame, output_frame)\n",
    "        \n",
    "#         # Add a small delay to control display speed\n",
    "#         cv2.waitKey(int(1000/fps))\n",
    "        \n",
    "# except KeyboardInterrupt:\n",
    "#     print(\"Interrupted by user\")\n",
    "# finally:\n",
    "#     cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tracking with Kalman Filters\n",
    "\n",
    "Tutorial Guide: https://machinelearningspace.com/2d-object-tracking-using-kalman-filter/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tracking using the Kalman Filter tracker from OpenCV\n",
    "\n",
    "try:\n",
    "    \n",
    "    # Initialize tracker as none\n",
    "    tracker = None\n",
    "    old_frame = None\n",
    "    old_gray = None\n",
    "    \n",
    "    # Luka-Kanade parameters\n",
    "    lk_params = dict(winSize=(15, 15),\n",
    "                 maxLevel=2,\n",
    "                 criteria=(cv2.TERM_CRITERIA_EPS |\n",
    "                           cv2.TERM_CRITERIA_COUNT, 10, 0.03))\n",
    "\n",
    "    \n",
    "    # Define the Kalman Filter\n",
    "    kf = KalmanFilter(0.1, 1, 1, 1, 0.1,0.1)\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "            continue\n",
    "        \n",
    "        output_frame = frame.copy()\n",
    "        \n",
    "        # If tracking is not started, look for initial fingertip to start tracking.\n",
    "        if not tracking_started:\n",
    "            \n",
    "            # Detect the initial point using the MediaPipe library\n",
    "            initial_point = detect_initial_point(frame)\n",
    "            \n",
    "            if initial_point is not None:\n",
    "                tracking_started = True\n",
    "                print(\"Initial point detected! Starting tracking...\")\n",
    "                \n",
    "                # Set current point for Kalman Filter\n",
    "                current_point = initial_point\n",
    "                \n",
    "                # Set current point for Lukas-Kanade tracker\n",
    "                p0 = np.array([[current_point[0], current_point[1]]], dtype=np.float32).reshape(-1, 1, 2)\n",
    "            \n",
    "            old_frame = frame\n",
    "            #old_frame = cv2.flip(old_frame, 1)\n",
    "            old_gray = cv2.cvtColor(old_frame, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        if tracking_started:\n",
    "            # Get the current frame\n",
    "            frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "            \n",
    "            # Get the Kalman Filter prediction\n",
    "            (kalman_pred_x, kalman_pred_y) = kf.predict()\n",
    "            \n",
    "            # Get the measurement from Lukas-Kanade tracker for Kalman update step\n",
    "            p1, st, err = cv2.calcOpticalFlowPyrLK(old_gray, frame_gray, p0, None, **lk_params)\n",
    "            \n",
    "            # If Lukas-Kanade tracker is successful, update the Kalman Filter\n",
    "            if st[0][0] == 1:\n",
    "                # Good point found - use it as measurement\n",
    "                measurement = p1.reshape(-1, 2)\n",
    "                x_meas, y_meas = measurement[0]\n",
    "                \n",
    "                # Update the Kalman Filter \n",
    "                (kalman_updated_x, kalman_updated_y) = kf.update([[x_meas], [y_meas]])\n",
    "                \n",
    "                # Plot the Kalman predicted and the updated points\n",
    "                cv2.circle(output_frame, (int(kalman_pred_x), int(kalman_pred_y)), 5, (0, 255, 255), -1)  # Predicted point in yellow\n",
    "                \n",
    "                cv2.circle(output_frame, (int(kalman_updated_x), int(kalman_updated_y)), 5, (0, 255, 0), -1)  # Updated point in green\n",
    "                \n",
    "                cv2.rectangle(output_frame, \n",
    "                              (int(kalman_updated_x - 15), int(kalman_updated_y - 15)), \n",
    "                              (int(kalman_updated_x + 15), int(kalman_updated_y + 15)),\n",
    "                              (255, 0, 0), 2)\n",
    "                cv2.putText(output_frame, \"Tracking Active\", (10, 30),\n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "                \n",
    "                # Update the p0 for Lukas-Kanade tracker\n",
    "                p0 = p1.reshape(-1, 1, 2)\n",
    "                \n",
    "                # Update the old frame and old gray frame\n",
    "                old_frame = frame\n",
    "                old_gray = frame_gray\n",
    "            else:\n",
    "                \n",
    "                # If Lukas-Kanade tracker is not successful, use Kalman Filter prediction as previous point\n",
    "                p0 = np.array([[kalman_pred_x, kalman_pred_y]], dtype=np.float32).reshape(-1, 1, 2)\n",
    "                \n",
    "                # Display the Kalman Filter prediction\n",
    "                cv2.circle(output_frame, (int(kalman_pred_x), int(kalman_pred_y)), 5, (0, 255, 255), -1)\n",
    "                cv2.rectangle(output_frame, \n",
    "                              (int(kalman_pred_x - 15), int(kalman_pred_y - 15)), \n",
    "                              (int(kalman_pred_x + 15), int(kalman_pred_y + 15)),\n",
    "                              (255, 0, 0), 2)\n",
    "                cv2.putText(output_frame, \"Tracking Lost - Kalman Guesses only\", (10, 30),\n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "                tracking_started = False\n",
    "        else:\n",
    "            cv2.putText(output_frame, \"Waiting for pointing gesture...\", (10, 30),\n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "        \n",
    "        # Display the frame in jupyter notebook or OpenCV window\n",
    "        display_cv2(frame, output_frame)\n",
    "        \n",
    "        # Add a small delay to control display speed\n",
    "        cv2.waitKey(int(1000/fps))\n",
    "        \n",
    "except KeyboardInterrupt:\n",
    "    print(\"Interrupted by user\")\n",
    "finally:\n",
    "    cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
