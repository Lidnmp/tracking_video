{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0a0ad9c-36d8-44a7-8936-271fde00bb07",
   "metadata": {},
   "source": [
    "### Hand tracking\n",
    "This algorithm detects and tracks the index finger of the hand to create a drawing when the index finger is extended. If the index finger is not extended, no drawing is made. When no hand is detected, the generated drawing is saved.  \n",
    "\n",
    "Assumptions for the algorithm:\n",
    "\n",
    "- Only one hand will be present on camera.\n",
    "- The hand should be positioned in the middle of the video frame's height.\n",
    "- The drawing must be continuous with no discontinuities.\n",
    "\n",
    "Sources used use the library mediapipe focused on the hand detection.  \n",
    "https://omes-va.com/mediapipe-hands-python/  \n",
    "https://omes-va.com/contando-dedos-mediapipe-opencv-python/  \n",
    "https://www.toolify.ai/es/ai-news-es/domina-la-deteccin-de-manos-y-la-estimacin-de-posturas-con-mediapipe-443934  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "162c027b-3a3d-4508-a0b5-e376956773f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a76363c-7d02-49a9-9d68-1daf4a19f90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_video_writer(cap):\n",
    "    \"\"\"\n",
    "    Initialize VideoWriter to save the video \n",
    "    with attributes from the video loaded.\n",
    "        \n",
    "    Args:\n",
    "        cap (cv2.VideoCapture): Loaded video.\n",
    "        \n",
    "    Returns:\n",
    "        VideoWriter: Interface for writing video files.\n",
    "    \"\"\"\n",
    "    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v') \n",
    "    return cv2.VideoWriter('output_hand_video.mp4', fourcc, fps, (frame_width, frame_height))\n",
    "    \n",
    "def meanshift_tip_points(index_tip,frame_hsv):\n",
    "    \"\"\"\n",
    "    Set up the ROI for tracking, and the termination criteria.\n",
    "    Apply meanshift to obtain the new location.\n",
    "        \n",
    "    Args:\n",
    "        index_tip(landmark): Instance of the Landmark class. \n",
    "            to obtain the coordinates from the tip.\n",
    "        frame_hsv (np.ndarray): Current frame from the video in HSV.\n",
    "        \n",
    "    Returns:\n",
    "        int: Coordinate x.\n",
    "        int: Coordinate y.\n",
    "    \"\"\"    \n",
    "    h, w, _ = frame_hsv.shape\n",
    "    # Normalize coordinates into pixels\n",
    "    tip_x, tip_y = int(index_tip.x * w), int(index_tip.y * h)     \n",
    "    term_crit = ( cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 1 )\n",
    "    w, h = 5, 5 # simply hardcoded the values\n",
    "    # Setup initial location of window\n",
    "    track_window = (tip_x, tip_y, w, h)\n",
    "    # set up the ROI for tracking\n",
    "    roi = frame_hsv[tip_y:tip_y+h, tip_x:tip_x+w]\n",
    "    hsv_roi =  cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)\n",
    "    #Establish ranges in HSV for the skin color \n",
    "    mask = cv2.inRange(hsv_roi, np.array((9., 102., 173.)), np.array((11., 145., 230.)))\n",
    "    roi_hist = cv2.calcHist([hsv_roi],[0],mask,[180],[0,180])\n",
    "    cv2.normalize(roi_hist,roi_hist,0,255,cv2.NORM_MINMAX)\n",
    "    dst = cv2.calcBackProject([frame_hsv],[0],roi_hist,[0,180],1)\n",
    "    # Apply meanshift to get the new location\n",
    "    ret, track_window = cv2.meanShift(dst, track_window, term_crit)\n",
    "    x,y,_,_ = track_window\n",
    "    return x,y\n",
    "\n",
    "def update_draw_points(paint_points, x,y):\n",
    "    \"\"\"\n",
    "    Add new draw points into the array paint_points.\n",
    "        \n",
    "    Args:\n",
    "        paint_points(np.ndarray): List of points from the draw.\n",
    "        x(int): Coordinate x.\n",
    "        y(int): Coordinate y.        \n",
    "    Returns:\n",
    "        np.ndarray: Array of coordinates [x,y]. \n",
    "    \"\"\"    \n",
    "    tmp_point = np.array([[x, y]], dtype=np.int32)\n",
    "    return np.append(paint_points,tmp_point,axis=0)\n",
    "    \n",
    "def is_index_finger_pointing(hand_landmarks):\n",
    "    \"\"\"\n",
    "    Method to check if the index finger is pointing or extended. \n",
    "        \n",
    "    Args:\n",
    "        hand_landmarks(NormalizedLandmarkList): List of landmarks.   \n",
    "    Returns:\n",
    "        boolean: If the distance betwwen the tip and base is greater \n",
    "            to the distance between base and wrist.\n",
    "    \"\"\"   \n",
    "    tip = np.array([hand_landmarks.landmark[8].x, hand_landmarks.landmark[8].y])\n",
    "    base = np.array([hand_landmarks.landmark[5].x, hand_landmarks.landmark[5].y])\n",
    "    wrist = np.array([hand_landmarks.landmark[0].x, hand_landmarks.landmark[0].y])\n",
    "    #\n",
    "    distance_tip_base = np.linalg.norm(tip - base)\n",
    "    distance_base_wrist = np.linalg.norm(base - wrist)\n",
    "    \n",
    "    return distance_tip_base > distance_base_wrist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aacde049-ff0f-49f9-9411-2179ca52c60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mp_hands = mp.solutions.hands\n",
    "\"\"\"\n",
    "Setting static_image_mode as False, to not to increase the computational cost, \n",
    "we do not apply the detector to all frames. \n",
    "As we know from advance in the video is there just one hand.\n",
    "Set min_detection_confidence with default value.\n",
    "\"\"\"\n",
    "hands = mp_hands.Hands(static_image_mode=False, max_num_hands=1, min_detection_confidence=0.5)\n",
    "\n",
    "video_path = \"hand_video.mp4\"\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "out = initialize_video_writer(cap)\n",
    "\n",
    "# List of points used for the draw\n",
    "paint_points= np.empty((0, 2), dtype=np.int32)\n",
    "#Flag to control the creation of the images from the draw.\n",
    "frame_saved = False\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "        \n",
    "    frame_hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results = hands.process(frame_rgb)\n",
    "    index_tip,term_crit, roi_hist, track_window =None, None, None, None\n",
    "   \n",
    "    if results.multi_hand_landmarks:\n",
    "        for hand_landmarks in results.multi_hand_landmarks:\n",
    "            \n",
    "            if is_index_finger_pointing(hand_landmarks):\n",
    "                index_tip = hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_TIP] #Represents the index finger tip\n",
    "                #Applay the tracking to index finger tip\n",
    "                x,y=meanshift_tip_points(index_tip,frame_hsv)\n",
    "                paint_points=update_draw_points(paint_points,x,y)\n",
    "                cv2.putText(frame, \"Drawing\", (10, 30),cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "                #Draw blue line to follow the index tip\n",
    "                cv2.polylines(frame, [paint_points], isClosed=False, color=(255,0,0), thickness=2)\n",
    "            else:\n",
    "                cv2.putText(frame, \"Hand detected not drawing\", (10, 30),cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "    else:\n",
    "        if not frame_saved and paint_points.size!=0:\n",
    "            cv2.polylines(frame, [paint_points], isClosed=False, color=(255,0,0), thickness=2)\n",
    "            current_frame = int(cap.get(cv2.CAP_PROP_POS_FRAMES))\n",
    "            cv2.imwrite(f'frame_{current_frame}.jpg', frame)\n",
    "            frame_saved = True\n",
    "            cv2.putText(frame, \"Saving frame with draw...\", (10, 65),cv2.FONT_HERSHEY_SIMPLEX, 1, (255,0,0), 2)\n",
    "        cv2.putText(frame, \"No hand detected...\", (10, 30),cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "        paint_points=np.delete(paint_points, slice(None), axis=0)\n",
    "\n",
    "    cv2.imshow(\"Index finger Detection\", frame)\n",
    "    out.write(frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "    frame_saved = False\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbbfed1f-de73-4518-b405-78e42d8cddce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
